#  #201117 

# 1바이트/ASCII/Unicode

<contents>

```js
1.1byte 메모리셀 
2.ASCII code
3.unicode(UTF-18)
```

---

## 1byte 메모리 셀 

### 메모리 저장단위 

> 바이트(byte) vs 비트(bit)

- 비트(bit)

  > 메모리에 데이터를 저장할 때 사용하는 최소단위 

- 바이트(byte)

  > 비트가 아닌 8개의 비트를 그룹 지은 것 

  |                                | 비트                         | 바이트        |
  | ------------------------------ | ---------------------------- | ------------- |
  | 연산장치, 메모리 기본관리 단위 | 데이터를 연산, 관리하면 불편 | 바이트로 관리 |

<img src="/Users/jeonsejin/Desktop/스크린샷 2020-11-18 오후 1.33.26.png" alt="스크린샷 2020-11-18 오후 1.33.26" style="zoom: 50%;" /> 

```js
//컴퓨터는 2진수의 0과 1형태만 이해하고 사용할 수 있습니다.
//byte :8개의 단위의 비트(8bit)를 하나의 그룹으로 사용하는 것
//>주소 지정이 가능한 단일 저장소 
//>1바이트: 0-255까지의 값 저장 

//bit(binary): 1은 전원의 'on'/ 0은 전원의 'off'
//Q) 1byte = 8bit ?
//A) ASCII Code(데이터 문자) 조사하기 
	  // Unicode 조사하기 
```



## 아스키 코드와 유니코드 

컴퓨터가 자료를 표현하기 위해서는 전기가 필요하다 

전기가 있는 것은 '1' 없는 것은 '0' => 비트 (bit)
그러나, 인간문자는 두 가지로만 나타낼 수 없어서 바이트(byte)단위 사용!



## 바이트(byte)?

> 일정한 개수(1-8바이트)의 비트로 이루어진 연속의 비트열 
>
> > 비트는 0 과1 두개를 표현하는데 > 2 ^ 8= 256개를 표현할 수 있다 (바이트)
> >
> > =>숫자와영어를 표현하고 남는 공간에 특수문자까지 할당할 수 있게 되었다.



## 아스키코드(ASCII code)

왜 등장했는가?

> 컴퓨터는 a,b,c,우리가 사용하는 언어를 알지 못하기 때문에 
> 컴퓨터가 알아들을 수 있게 입력해줘야 하는데 a=1이고 b=2이야라고 설정을 
> 해두어도 기준이 없기 때문에 어떤기기는 a =2라고 할 수도 있고 1이라고 
> 할수도 있다 
>
> =>글씨가 깨지는 문제가 발생 
> =>문자와 숫자를 매칭시키는 국제적인 규칙을 만든다 =>아스키 코드 



#### 아스키코드의 문자표?

> 문자표 : 1:1매칭시킨 표를 말한다. (characterSet)

아스키코드는 1바이트, 즉 8비트의 데이터를 사용한다. 

대표적인 예로, 표를 참고하면 a는 이진수 100 0001로 변환된다. 

어? 표의 이진수가 7자리네? 하나 어디갔지?

> 한자리 = 패리티 비트(parity bit)
>
> > 데이터의 에러를 탐지하기 위해 사용
> > 일곱자리의 이진수에서  '1'이 홀수개하면 끝에 1
> > '1'이 짝수개라면 끝에 0을 덧붙인다. 

=>아스키코드는 패리티 비트를 제외하고 총 7자리의 이진수를 문자로 나타낼 수 있다.

=>2^7 =128개의 문자를 나타낼 수 있다. 



#### 문제점 ) 아스키코드의 "A" =american

> 영어만 존재한다.
> 아스키코드표가 만들어질 때는 영어권 사람들만 주로 컴퓨터를 이용했는데 
> 시간이 지나면서 여러나라에서 컴퓨터를 사용하게 되면서 다양한 표준들이 생성
>
> =>다양한 표준들이 충돌하고 문자가 깨지는 현상이 발생 
>
> =>많은 표준을 하나로 합칠 새로운 기준 필요!



## 유니코드(unicode)

> 아스키코드로 모든언어를 표현하는데 한계가 존재 
>
> => 전세계 언어의 문자를 정의하기 위해서 등장 
>
> => 1바이트로 부족했으니 용량확장한 2바이트(2^16)을 사용하게 된다.
>
> =>후에 더 추가 



### 문제점) 가변적인 표현의 문제

> 유니코드가 영어를 표현할 땐 1바이트
> 한글을 표현할 땐 2바이트
> 특수문자를 표현할 땐 3바이트
>
> =>컴퓨터에게 혼란 =>기준을 정해줘!



#### 유니코드 인코딩 방식

> 컴퓨터에게 어떤 글자를 만났을 때 얼만큼씩 읽어야 하는지 미리 말해주는 것 
>
> 방식 )
>
> > 1)UCS-2/4 : 코드 포인트를 코드화한 것 
> >
> > 2) UTF-7, UTF-8, UTF-16, UTF-32 : 변환 인코딩 형식
> >
> > > UTF-8: 문자열 집합과 인코딩 형태를 8비트 단위로 한다 



#### 가변 길이 인코딩 방식: 유니코드 한 문자를 나타내기 위해서 1-4바이트 사용

왜 가변적으로 인코딩 할까? 일정하게 4바이트 하면 안될까?

> 아스키문자들은 1바이트로 하나의 문자를 표현할 수 있는데 모든 문자를 4바이트로 사용하면 저장소가 지나치게 낭비된다. 
> => 아스키코드로 표현가능한 것은 1바이트로 표현하고 안되면 2바이트! (UTF-8)



그렇다면 어떻게 1바이트로 읽을지 4바이트로 읽을지 알수있지?

> 첫번째 바이트를 시작하는 비트가 어떤것이냐를 보면 알 수 있다. 
>
> 0xxxxxxx : 
> 첫 번째 바이트가 0으로 시작한다면 0이외의 7 비트를 아스키로 인식한다.
> 110xxxxx 10xxxxxx 두번째 바이트까지 읽어서 하나의 문자로 표현
> 1110xxxx 10xxxxxx 10xxxxxx 세번째 바이트까지 읽어서 하나의 문자로 표현
> 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx 네번째 바이트까지 읽어서 하나의 문자로 표현

=>	UTF-8은 아스키방식과 완벽하게 호환된다는 것 